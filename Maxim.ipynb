{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA5xYy3KVpd3",
        "outputId": "9741136b-3fc6-4f85-d9d8-fd76309c8816"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision transformers timm tifffile matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9K3B5gnU_R_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from transformers import AutoImageProcessor, AutoModelForImageToImage\n",
        "from PIL import Image\n",
        "import tifffile as tiff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rTpaw9phQUc",
        "outputId": "3dc17ada-e7b6-4cd1-ba31-6b2a30031f69"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "Pj_LpBIIjV9U",
        "outputId": "a8c1887d-3807-4dae-9968-444ab9a07849"
      },
      "outputs": [],
      "source": [
        "# Load the Hugging Face MAXIM Dehazing model\n",
        "from transformers import AutoImageProcessor, AutoModelForImageToImage\n",
        "from huggingface_hub import HfFolder  # Import HfFolder for loading the token\n",
        "\n",
        "# Load the token from the stored location\n",
        "token = HfFolder.get_token()\n",
        "\n",
        "# Use the loaded token when loading the model\n",
        "processor = AutoImageProcessor.from_pretrained(\"google/maxim-s2-dehazing-sots-outdoor\", token=token)\n",
        "model = AutoModelForImageToImage.from_pretrained(\"google/maxim-s2-dehazing-sots-outdoor\", token=token)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ughEbldVizo"
      },
      "outputs": [],
      "source": [
        "# TIFF image loader and preprocessor\n",
        "def load_tiff_image(file_path):\n",
        "    img = tiff.imread(file_path)\n",
        "    if img.ndim == 2:\n",
        "        img = np.stack([img] * 3, axis=-1)\n",
        "    elif img.ndim == 3:\n",
        "        if img.shape[0] == 3:\n",
        "            img = np.transpose(img, (1, 2, 0))\n",
        "        if img.shape[-1] > 3:\n",
        "            img = img[:, :, :3]\n",
        "    img = Image.fromarray(np.uint8(img))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOhDxI7cViRL"
      },
      "outputs": [],
      "source": [
        "# Run inference using the model\n",
        "def dehaze_image(image):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    output_image = processor.post_process(outputs, output_type=\"pil\")[0]\n",
        "    return output_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI_WhIKNVcGl"
      },
      "outputs": [],
      "source": [
        "# Visualize attention map (last layer average)\n",
        "def visualize_attention(image, model, processor):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "\n",
        "    # Extract attention from last layer\n",
        "    attention_maps = outputs.attentions[-1]\n",
        "    avg_attention = attention_maps.mean(dim=1)[0]  # average over heads\n",
        "\n",
        "    # Take attention from [CLS] to all tokens and reshape\n",
        "    attn_weights = avg_attention[0, 1:]\n",
        "    num_patches = int(attn_weights.shape[0] ** 0.5)\n",
        "    attn_map = attn_weights.reshape(num_patches, num_patches).cpu().numpy()\n",
        "\n",
        "    # Resize attention map to image size\n",
        "    attn_map = cv2.resize(attn_map, image.size)\n",
        "    attn_map = (attn_map - attn_map.min()) / (attn_map.max() - attn_map.min())\n",
        "\n",
        "    # Overlay attention on image\n",
        "    image_np = np.array(image).astype(np.float32)\n",
        "    heatmap = (attn_map[..., None] * 255).astype(np.uint8)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    overlay = cv2.addWeighted(image_np.astype(np.uint8), 0.6, heatmap_colored, 0.4, 0)\n",
        "    return Image.fromarray(overlay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAP2PstKVXHq"
      },
      "outputs": [],
      "source": [
        "# Main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Single Image Dehazing with XAI\")\n",
        "    parser.add_argument(\"--input\", type=str, required=True, help=\"Path to input .tiff image\")\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"outputs\", help=\"Directory to save outputs\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    # Load and process image\n",
        "    image = load_tiff_image(args.input)\n",
        "    dehazed = dehaze_image(image)\n",
        "    attention_overlay = visualize_attention(image, model, processor)\n",
        "\n",
        "    # Save outputs\n",
        "    input_name = os.path.splitext(os.path.basename(args.input))[0]\n",
        "    image.save(os.path.join(args.output_dir, f\"{input_name}_original.png\"))\n",
        "    dehazed.save(os.path.join(args.output_dir, f\"{input_name}_dehazed.png\"))\n",
        "    attention_overlay.save(os.path.join(args.output_dir, f\"{input_name}_attention.png\"))\n",
        "\n",
        "    print(\"Processing complete. Outputs saved to:\", args.output_dir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
